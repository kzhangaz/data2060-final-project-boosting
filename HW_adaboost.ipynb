{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW_adaboost.py\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "    \n",
    "class AdaBoostClassifier:\n",
    "    \"\"\"\n",
    "    AdaBoost (Adaptive Boosting) Classifier\n",
    "    An ensemble learning algorithm that combines multiple weak classifiers to build a strong classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_estimators=50):\n",
    "        \"\"\"\n",
    "        Initialize the AdaBoost classifier.\n",
    "\n",
    "        Parameters:\n",
    "        - n_estimators: Number of weak classifiers to use.\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.w = []  # Store the weights of the classifiers\n",
    "        self.models = []  # Store the weak classifiers\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the AdaBoost model to the training data.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Training data, shape (n_samples, n_features)\n",
    "        - y: Target labels, shape (n_samples,)\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        # Initialize weights uniformly\n",
    "        D = np.ones(n_samples) / n_samples  \n",
    "\n",
    "        for t in range(self.n_estimators):\n",
    "            # Create a weak classifier (decision stump)\n",
    "            model = DecisionTreeClassifier(max_depth=2)  \n",
    "            model.fit(X, y, sample_weight=D)  # Fit model with sample weights\n",
    "            y_pred = model.predict(X)  # Predictions from the model\n",
    "\n",
    "            # Calculate the weighted error\n",
    "            error = np.sum(D * (y_pred != y))  # Weighted error\n",
    "\n",
    "            # Error cannot be exactly 0.5 because it represents the weighted sum of misclassifications.\n",
    "            # If error is 0.5, it means the model is performing no better than random guessing,\n",
    "            # This means the model is not contributing to the ensemble learning process,\n",
    "            # and the weights D will not be updated, leading to no improvement in the model.\n",
    "            if error == 0.5:\n",
    "                print(\"Warning: Error is 0.5, stopping training.\")\n",
    "                break\n",
    "\n",
    "            # Calculate the weight for the weak classifier\n",
    "            w_t = 0.5 * np.log((1.0 - error) / (error + 1e-10))  # Avoid division by zero\n",
    "\n",
    "            # Update weights for the next iteration\n",
    "            D *= np.exp(-w_t * y * y_pred)  # Update weights based on prediction\n",
    "            D /= np.sum(D * np.exp(-w_t * y * y_pred))  # Normalize weights\n",
    "\n",
    "\n",
    "            self.models.append(model)  # Store the model\n",
    "            self.w.append(w_t)  # Store the w_t\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class labels for the input data.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input data, shape (n_samples, n_features)\n",
    "\n",
    "        Returns:\n",
    "        - Predicted class labels, shape (n_samples,)\n",
    "        \"\"\"\n",
    "        pred = np.zeros(X.shape[0])  # Initialize predictions\n",
    "        for w_i, model in zip(self.w, self.models):\n",
    "            pred += w_i * model.predict(X)  # Weighted sum of predictions\n",
    "        return np.sign(pred)  # Return the sign of the predictions\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculate the accuracy of the model.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input data, shape (n_samples, n_features)\n",
    "        - y: True labels, shape (n_samples,)\n",
    "\n",
    "        Returns:\n",
    "        - Accuracy as a float.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X)  # Get predictions\n",
    "        accuracy = np.mean(predictions == y)  # Calculate accuracy\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "import numpy as np\n",
    "\n",
    "# Sets random seed for testing purposes\n",
    "np.random.seed(0)\n",
    "\n",
    "# Creates Test Models\n",
    "test_model1 = AdaBoostClassifier(n_estimators=10)\n",
    "test_model2 = AdaBoostClassifier(n_estimators=50)\n",
    "test_model3 = AdaBoostClassifier(n_estimators=20)\n",
    "\n",
    "# Creates Test Data\n",
    "x1 = np.array([[0, 0], [1, 1], [1, 0], [0, 1]])\n",
    "y1 = np.array([-1, -1, 1, 1])  # Labels should be -1 and 1 for AdaBoost\n",
    "\n",
    "x2 = np.array([[0, 0], [1, 1], [1, 0], [0, 1], [0, 2], [1, 2]])\n",
    "y2 = np.array([-1, -1, 1, 1, -1, 1])  # More complex dataset\n",
    "\n",
    "x3 = np.array([[0, 0], [1, 1], [2, 2], [3, 3], [4, 4], [5, 5]])\n",
    "y3 = np.array([-1, -1, 1, 1, 1, 1])  # Another dataset\n",
    "\n",
    "# Test Model Train\n",
    "def check_train_dtype(model, X, y):\n",
    "    assert isinstance(model.models, list)\n",
    "    assert len(model.models) > 0, \"Model should have trained at least one weak learner.\"\n",
    "    assert len(model.w) == len(model.models), \"Weights should match the number of models.\"\n",
    "\n",
    "# Train the models\n",
    "test_model1.train(x1, y1)\n",
    "check_train_dtype(test_model1, x1, y1)\n",
    "\n",
    "test_model2.train(x2, y2)\n",
    "check_train_dtype(test_model2, x2, y2)\n",
    "\n",
    "test_model3.train(x3, y3)\n",
    "check_train_dtype(test_model3, x3, y3)\n",
    "\n",
    "# Test Model Predictions\n",
    "def check_test_dtype(pred, X_test):\n",
    "    assert isinstance(pred, np.ndarray)\n",
    "    assert pred.ndim == 1 and pred.shape == (X_test.shape[0],)\n",
    "\n",
    "# Make predictions\n",
    "pred1 = test_model1.predict(x1)\n",
    "check_test_dtype(pred1, x1)\n",
    "assert (pred1 == y1).all(), \"Predictions should match the expected labels for model 1.\"\n",
    "\n",
    "pred2 = test_model2.predict(x2)\n",
    "check_test_dtype(pred2, x2)\n",
    "assert (pred2 == y2).all(), \"Predictions should match the expected labels for model 2.\"\n",
    "\n",
    "pred3 = test_model3.predict(x3)\n",
    "check_test_dtype(pred3, x3)\n",
    "assert (pred3 == y3).all(), \"Predictions should match the expected labels for model 3.\"\n",
    "\n",
    "# Test Model Accuracy\n",
    "def check_accuracy(model, X, y, expected_accuracy):\n",
    "    accuracy = model.accuracy(X, y)\n",
    "    assert accuracy == expected_accuracy, f\"Expected accuracy: {expected_accuracy}, but got: {accuracy}\"\n",
    "\n",
    "# Check accuracy\n",
    "check_accuracy(test_model1, x1, y1, 1.0)  # Expecting 100% accuracy for this simple case\n",
    "check_accuracy(test_model2, x2, y2, 1.0)  # Expecting 100% accuracy for this dataset\n",
    "check_accuracy(test_model3, x3, y3, 1.0)  # Expecting 100% accuracy for this dataset\n",
    "\n",
    "# Additional Tests for Edge Cases\n",
    "def test_empty_train():\n",
    "    with pytest.raises(ValueError):\n",
    "        test_model1.train(np.array([]), np.array([]))\n",
    "\n",
    "def test_empty_predict():\n",
    "    with pytest.raises(ValueError):\n",
    "        test_model1.predict(np.array([]))\n",
    "\n",
    "def test_accuracy_empty():\n",
    "    with pytest.raises(ValueError):\n",
    "        test_model1.accuracy(np.array([]), np.array([]))\n",
    "\n",
    "# Run additional edge case tests\n",
    "test_empty_train()\n",
    "test_empty_predict()\n",
    "test_accuracy_empty()\n",
    "\n",
    "# Print a message indicating the tests have completed\n",
    "print(\"All tests completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data2060",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
