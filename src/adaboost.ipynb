{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Decision Tree (to use as weak learners in AdaBoostClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def node_score_error(prob):\n",
    "    '''\n",
    "        Calculate the node score using the train error of the subdataset and return it.\n",
    "        For a dataset with two classes, C(p) = min{p, 1-p}\n",
    "    '''\n",
    "    return min(prob, 1.0 - prob)\n",
    "\n",
    "def node_score_entropy(prob):\n",
    "    '''\n",
    "        Calculate the node score using the entropy of the subdataset and return it.\n",
    "        For a dataset with 2 classes, C(p) = -p * log(p) - (1-p) * log(1-p)\n",
    "        For the purposes of this calculation, assume 0*log0 = 0.\n",
    "        HINT: remember to consider the range of values that p can take!\n",
    "    '''\n",
    "    # HINT: If p < 0 or p > 1 then entropy = 0\n",
    "\n",
    "    if prob <= 0.0 or prob >= 1.0:\n",
    "        return 0.0\n",
    "    \n",
    "    return -prob * np.log(prob) - (1.0 - prob) * np.log(1.0 - prob)\n",
    "\n",
    "\n",
    "def node_score_gini(prob):\n",
    "    '''\n",
    "        Calculate the node score using the gini index of the subdataset and return it.\n",
    "        For dataset with 2 classes, C(p) = 2 * p * (1-p)\n",
    "    '''\n",
    "\n",
    "    return 2.0 * prob * (1.0 - prob)\n",
    "\n",
    "class Node:\n",
    "    '''\n",
    "    Helper to construct the tree structure.\n",
    "    '''\n",
    "    def __init__(self, left=None, right=None, depth=0, index_split_on=0, isleaf=False, label=1):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.depth = depth\n",
    "        self.index_split_on = index_split_on\n",
    "        self.isleaf = isleaf\n",
    "        self.label = label\n",
    "        self.info = {}  # used for visualization\n",
    "        self.threshold = None\n",
    "\n",
    "    def _set_info(self, gain, num_samples):\n",
    "        '''\n",
    "        Helper function to add to info attribute.\n",
    "        '''\n",
    "        self.info['gain'] = gain\n",
    "        self.info['num_samples'] = num_samples\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "\n",
    "    def __init__(self, data, gain_function=node_score_gini, max_depth=40, weight=None, converted=None):\n",
    "        # Initialize the decision tree with data and parameters.\n",
    "        if converted is not None:\n",
    "            for row in data:\n",
    "                if row[0] == -1:\n",
    "                    row[0] = 0  # Convert -1 to 0\n",
    "                    \n",
    "        self.majority_class = 1 if sum(row[0] for row in data) > len(data) / 2 else 0\n",
    "        self.max_depth = max_depth\n",
    "        self.root = Node(label=self.majority_class)\n",
    "        self.gain_function = gain_function\n",
    "        if weight is None:\n",
    "            self.sample_weight = np.ones(len(data)) / len(data)\n",
    "        else:\n",
    "            self.sample_weight = weight / np.sum(weight)\n",
    "\n",
    "        indices = list(range(1, len(data[0])))\n",
    "        self._split_recurs(self.root, data, indices, self.sample_weight)\n",
    "\n",
    "    def predict(self, features, converted=None):\n",
    "        '''\n",
    "        Predict the label for given features.\n",
    "        '''\n",
    "        if features.ndim == 1:  # 1d array\n",
    "            prediction = self._predict_recurs(self.root, features)\n",
    "            return -1 if converted and prediction == 0 else prediction\n",
    "        else:  # 2d array\n",
    "            predictions = []\n",
    "            for feature in features:\n",
    "                prediction = self._predict_recurs(self.root, feature)\n",
    "                if converted and prediction == 0:\n",
    "                    prediction = -1\n",
    "                predictions.append(prediction)\n",
    "            return np.array(predictions) \n",
    "\n",
    "    def accuracy(self, data):\n",
    "        '''\n",
    "        Calculate accuracy on the given data.\n",
    "        '''\n",
    "        return 1 - self.loss(data)\n",
    "\n",
    "    def loss(self, data):\n",
    "        '''\n",
    "        Calculate loss on the given data.\n",
    "        '''\n",
    "        test_Y = np.array([row[0] for row in data])  # Get the true labels\n",
    "        predictions = self.predict(np.array(data))  # Get the predicted results\n",
    "        return np.mean(predictions != test_Y) \n",
    "\n",
    "    def _predict_recurs(self, node, row):\n",
    "        '''\n",
    "        Predict label by traversing the tree.\n",
    "        '''\n",
    "        if node.isleaf or node.index_split_on == 0:\n",
    "            return node.label\n",
    "        split_index = node.index_split_on\n",
    "        if not row[split_index]:\n",
    "            return self._predict_recurs(node.left, row)\n",
    "        else:\n",
    "            return self._predict_recurs(node.right, row)\n",
    "\n",
    "\n",
    "    def _is_terminal(self, node, data, indices):\n",
    "        '''\n",
    "        Check if the node should stop splitting.\n",
    "        '''\n",
    "        y = [row[0] for row in data]\n",
    "\n",
    "        sumy = sum(row[0] for row in data)\n",
    "\n",
    "        if len(data) - sumy == sumy:\n",
    "            majority_label = self.majority_class\n",
    "        else:\n",
    "            majority_label = 1 if sumy > len(data) / 2 else 0\n",
    "\n",
    "        if len(set(y)) == 1:\n",
    "            return True, y[0]\n",
    "        if len(data) == 0:\n",
    "            return True, self.majority_class\n",
    "        if len(indices) == 0:\n",
    "            return True, majority_label\n",
    "\n",
    "        if node.depth >= self.max_depth:\n",
    "            return True, majority_label\n",
    "\n",
    "        return False, majority_label\n",
    "\n",
    "    def _split_recurs(self, node, data, indices, weights):\n",
    "        '''\n",
    "        Recursively split the node based on data.\n",
    "        '''\n",
    "        node.isleaf, node.label = self._is_terminal(node, data, indices)\n",
    "\n",
    "        if not node.isleaf:\n",
    "            max_gain = -1\n",
    "            best_threshold = None\n",
    "\n",
    "            for split_index in indices:\n",
    "                feature_values = sorted(set(row[split_index] for row in data))\n",
    "\n",
    "                for i in range(len(feature_values) - 1):\n",
    "                    threshold = (feature_values[i] + feature_values[i + 1]) / 2\n",
    "                    gain = self._calc_gain(data, split_index, self.gain_function, threshold, weights)\n",
    "\n",
    "                    if gain > max_gain:\n",
    "                        max_gain = gain\n",
    "                        node.index_split_on = split_index\n",
    "                        best_threshold = threshold\n",
    "\n",
    "                if len(feature_values) == 1:\n",
    "                    gain = self._calc_gain(data, split_index, self.gain_function, feature_values[0], weights)\n",
    "                    if gain > max_gain:\n",
    "                        max_gain = gain\n",
    "                        node.index_split_on = split_index\n",
    "                        best_threshold = feature_values[0]\n",
    "\n",
    "            node._set_info(max_gain, len(data))\n",
    "            node.threshold = best_threshold\n",
    "\n",
    "            node.left = Node(depth=node.depth + 1)\n",
    "            node.right = Node(depth=node.depth + 1)\n",
    "            indices.remove(node.index_split_on)\n",
    "\n",
    "            leftData = [row for row in data if row[node.index_split_on] <= node.threshold]\n",
    "            rightData = [row for row in data if row[node.index_split_on] > node.threshold]\n",
    "\n",
    "            left_weights = weights[[row[node.index_split_on] <= node.threshold for row in data]]\n",
    "            right_weights = weights[[row[node.index_split_on] > node.threshold for row in data]]\n",
    "\n",
    "            self._split_recurs(node.left, leftData, indices, left_weights)\n",
    "            self._split_recurs(node.right, rightData, indices, right_weights)\n",
    "        else:\n",
    "            node._set_info(0, len(data))\n",
    "\n",
    "    def _calc_gain(self, data, split_index, gain_function, threshold=None, weights=None):\n",
    "        '''\n",
    "        Calculate gain for the proposed split.\n",
    "        '''\n",
    "        if threshold is None:\n",
    "            threshold = 0.5\n",
    "        if weights is None:\n",
    "            weights = np.ones(len(data))  # Default weights\n",
    "        y = [row[0] for row in data]\n",
    "        xi = [1 if row[split_index] > threshold else 0 for row in data]\n",
    "        \n",
    "        if len(y) != 0 and len(xi) != 0:\n",
    "            total_weight = np.sum(weights)\n",
    "            probY = np.sum(weights * y) / total_weight\n",
    "            probX = np.sum(weights * xi) / total_weight\n",
    "\n",
    "            weights = weights.to_numpy() if isinstance(weights, pd.Series) else weights\n",
    "            y = np.array(y) if not isinstance(y, np.ndarray) else y\n",
    "            xi = np.array(xi) if not isinstance(xi, np.ndarray) else xi\n",
    "\n",
    "            y1x1 = sum(weights[index] for index in range(len(y)) if y[index] == 1 and xi[index] == 1)\n",
    "            y0x0 = sum(weights[index] for index in range(len(y)) if y[index] == 0 and xi[index] == 0)\n",
    "\n",
    "            prob1 = y1x1 / total_weight \n",
    "            prob2 = y0x0 / total_weight \n",
    "\n",
    "            probxi_true = (probX * gain_function(prob1 / probX)) if probX > 0 else 0\n",
    "            probxi_false = ((1.0 - probX) * gain_function(prob2 / (1.0 - probX))) if probX < 1.0 else 0\n",
    "\n",
    "            gain = gain_function(probY) - probxi_true - probxi_false\n",
    "        else:\n",
    "            gain = 0\n",
    "\n",
    "        return gain\n",
    "\n",
    "    def print_tree(self):\n",
    "        '''\n",
    "        Helper function for tree_visualization.\n",
    "        Only effective with very shallow trees.\n",
    "        You do not need to modify this.\n",
    "        '''\n",
    "        print('---START PRINT TREE---')\n",
    "        def print_subtree(node, indent=''):\n",
    "            if node is None:\n",
    "                return str(\"None\")\n",
    "            if node.isleaf:\n",
    "                return str(node.label)\n",
    "            else:\n",
    "                decision = 'split attribute = {:d}; gain = {:f}; number of samples = {:d}'.format(node.index_split_on, node.info['gain'], node.info['num_samples'])\n",
    "            left = indent + '0 -> '+ print_subtree(node.left, indent + '\\t\\t')\n",
    "            right = indent + '1 -> '+ print_subtree(node.right, indent + '\\t\\t')\n",
    "            return (decision + '\\n' + left + '\\n' + right)\n",
    "\n",
    "        print(print_subtree(self.root))\n",
    "        print('----END PRINT TREE---')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class AdaBoostClassifier:\n",
    "    \"\"\"\n",
    "    AdaBoost (Adaptive Boosting) Classifier\n",
    "    An ensemble learning algorithm that combines multiple weak classifiers to build a strong classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_estimators=10, max_depth=1):\n",
    "        \"\"\"\n",
    "        Initialize the AdaBoost classifier.\n",
    "\n",
    "        Parameters:\n",
    "        - n_estimators: Number of weak classifiers to use.\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth  # Store max_depth for DecisionTree\n",
    "        self.w = []  # Store the weights of the classifiers\n",
    "        self.models = []  # Store the weak classifiers\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the AdaBoost model to the training data.\n",
    "        For T WLs,\n",
    "        1. train WL (DecisionTree with max_depth=1)\n",
    "        2. compute error of this WL\n",
    "        3. compute the weight of this WL w_t and store it in self.w\n",
    "        4. compute and update the distribution D of the samples for WLs next\n",
    "\n",
    "        Parameters:\n",
    "        - X: Training data, shape (n_samples, n_features)\n",
    "        - y: Target labels, shape (n_samples,)\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        # Initialize weights uniformly\n",
    "        D = np.ones(n_samples) / n_samples  \n",
    "\n",
    "        for t in range(self.n_estimators):\n",
    "            '''\n",
    "            # sklearn\n",
    "            # Create a weak classifier (decision stump)\n",
    "            std_model = DecisionTreeClassifier(max_depth=2)  \n",
    "            # Fit the model to the training data\n",
    "            std_model.fit(X, y, sample_weight=D)  # Add this line to train the model\n",
    "            y_pred_sklearn = std_model.predict(X)\n",
    "            '''\n",
    "            # avoid extremely small sample weight\n",
    "            D = np.clip(D, a_min=np.finfo(D.dtype).eps, a_max=None)\n",
    "\n",
    "            weak_model = DecisionTree(data=np.column_stack((y, X)), max_depth=self.max_depth, weight=D, converted=True) \n",
    "            # weak_model = DecisionTreeClassifier(max_depth=self.max_depth)\n",
    "            # weak_model.fit(X, y, sample_weight=D) \n",
    "\n",
    "            y_pred = weak_model.predict(features=np.column_stack((y, X)), converted = True)\n",
    "            # y_pred = weak_model.predict(X)\n",
    "\n",
    "            # Calculate the weighted error\n",
    "            error = np.mean(np.average(y_pred != y, weights=D, axis=0))\n",
    "\n",
    "            # Calculate the weight for the weak classifier\n",
    "            w_t = 0.5 * np.log((1.0 - error) / (error + 1e-10))  # Avoid division by zero\n",
    "\n",
    "            # Update weights for the next iteration\n",
    "            D *= np.exp(-w_t * y * y_pred)  # Update weights based on prediction\n",
    "            D /= np.sum(D * np.exp(-w_t * y * y_pred))  # Normalize weights\n",
    "\n",
    "            self.models.append(weak_model)  # Store the model\n",
    "            self.w.append(w_t)  # Store the w_t\n",
    "\n",
    "    def predict(self, X, converted = True):\n",
    "        \"\"\"\n",
    "        Predict the class labels for the input data.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input data, shape (n_samples, n_features)\n",
    "\n",
    "        Returns:\n",
    "        - Predicted class labels, shape (n_samples,)\n",
    "        \"\"\"\n",
    "        pred = np.zeros(X.shape[0])  # Initialize predictions\n",
    "        X_with_zero = np.insert(X, 0, 0, axis=1)  # Insert 0 at the beginning of each row\n",
    "        for w_i, model in zip(self.w, self.models):\n",
    "            pred += w_i * model.predict(X_with_zero, converted)  # Weighted sum of predictions\n",
    "            # pred += w_i * model.predict(X)\n",
    "        return np.sign(pred)  # Return the sign of the predictions\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        \"\"\"\n",
    "        Calculate the accuracy of the model.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input data, shape (n_samples, n_features)\n",
    "        - y: True labels, shape (n_samples,)\n",
    "\n",
    "        Returns:\n",
    "        - Accuracy as a float.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X)  # Get predictions\n",
    "        accuracy = np.mean(predictions == y)  # Calculate accuracy\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check Model**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "     # Create a simple dataset\n",
    "     X = np.array([\n",
    "        [0, 0, 1, 0],\n",
    "        [1, 1, 0, 1],\n",
    "        [1, 0, 1, 0],\n",
    "        [0, 1, 0, 1],\n",
    "        [0, 0, 0, 0],\n",
    "        [1, 1, 1, 1],\n",
    "        [0, 1, 1, 0],\n",
    "        [1, 0, 0, 1],\n",
    "        [1, 1, 0, 0],\n",
    "        [0, 0, 1, 1]\n",
    "    ])  # 10 samples with 4 features\n",
    "\n",
    "     y = np.array([-1, 1, 1, -1, -1, 1, 1, -1, 1, -1])  # Binary labels (-1 and 1)\n",
    "     # Initialize the AdaBoost classifier\n",
    "     model = AdaBoostClassifier(n_estimators=10, max_depth=1)\n",
    "\n",
    "     # Train the model\n",
    "     model.train(X, y)\n",
    "\n",
    "     # Calculate accuracy\n",
    "     accuracy = model.accuracy(X, y)\n",
    "\n",
    "     # Print results\n",
    "     print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "import numpy as np\n",
    "\n",
    "# Sets random seed for testing purposes\n",
    "np.random.seed(0)\n",
    "\n",
    "# Creates Test Models\n",
    "test_model1 = AdaBoostClassifier(n_estimators=10)\n",
    "test_model2 = AdaBoostClassifier(n_estimators=50)\n",
    "test_model3 = AdaBoostClassifier(n_estimators=20)\n",
    "\n",
    "# Dataset 1\n",
    "x1 = np.array([\n",
    "    [0, 0, 1, 0],\n",
    "    [1, 1, 0, 1],\n",
    "    [1, 0, 1, 0],\n",
    "    [0, 1, 0, 1],\n",
    "    [0, 0, 0, 0],\n",
    "    [1, 1, 1, 1],\n",
    "    [0, 1, 1, 0],\n",
    "    [1, 0, 0, 1],\n",
    "    [1, 1, 0, 0],\n",
    "    [0, 0, 1, 1]\n",
    "])  # 10 samples with 4 features\n",
    "\n",
    "y1 = np.array([-1, 1, 1, -1, -1, 1, 1, -1, 1, -1])  # Binary labels (-1 and 1)\n",
    "\n",
    "# Dataset 2\n",
    "x2 = np.array([\n",
    "    [0, 1, 0, 1, 1, 0],\n",
    "    [1, 0, 1, 0, 0, 1],\n",
    "    [1, 1, 0, 1, 0, 0],\n",
    "    [0, 0, 1, 1, 1, 1],\n",
    "    [1, 0, 0, 0, 1, 0],\n",
    "    [0, 1, 1, 0, 0, 1],\n",
    "    [1, 1, 1, 0, 1, 1],\n",
    "    [0, 0, 0, 1, 0, 0],\n",
    "    [1, 0, 1, 1, 1, 0],\n",
    "    [0, 1, 0, 0, 1, 1]\n",
    "])  # 10 samples with 6 features\n",
    "\n",
    "y2 = np.array([-1, 1, 1, -1, 1, -1, 1, -1, 1, -1])  # Binary labels (-1 and 1)\n",
    "\n",
    "# Dataset 3\n",
    "x3 = np.array([\n",
    "    [1, 1, 0, 0, 1, 1],\n",
    "    [0, 0, 1, 1, 0, 0],\n",
    "    [1, 0, 1, 0, 1, 0],\n",
    "    [0, 1, 0, 1, 1, 1],\n",
    "    [1, 1, 1, 0, 0, 1],\n",
    "    [0, 0, 0, 1, 0, 1],\n",
    "    [1, 0, 0, 1, 1, 0],\n",
    "    [0, 1, 1, 0, 1, 1],\n",
    "    [1, 1, 1, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 1, 0]\n",
    "])  # 10 samples with 6 features\n",
    "\n",
    "y3 = np.array([1, -1, 1, -1, 1, -1, 1, -1, 1, -1])  # Binary labels (-1 and 1)\n",
    "\n",
    "# Test Model Train\n",
    "def check_train_dtype(model, X, y):\n",
    "    assert isinstance(model.models, list)\n",
    "    assert len(model.models) > 0, \"Model should have trained at least one weak learner.\"\n",
    "    assert len(model.w) == len(model.models), \"Weights should match the number of models.\"\n",
    "\n",
    "# Train the models\n",
    "test_model1.train(x1, y1)\n",
    "check_train_dtype(test_model1, x1, y1)\n",
    "\n",
    "test_model2.train(x2, y2)\n",
    "check_train_dtype(test_model2, x2, y2)\n",
    "\n",
    "test_model3.train(x3, y3)\n",
    "check_train_dtype(test_model3, x3, y3)\n",
    "\n",
    "# Test Model Predictions\n",
    "def check_test_dtype(pred, X_test):\n",
    "    assert isinstance(pred, np.ndarray)\n",
    "    assert pred.ndim == 1 and pred.shape == (X_test.shape[0],)\n",
    "\n",
    "# Make predictions\n",
    "pred1 = test_model1.predict(x1)\n",
    "check_test_dtype(pred1, x1)\n",
    "assert (pred1 == y1).all(), \"Predictions should match the expected labels for model 1.\"\n",
    "\n",
    "pred2 = test_model2.predict(x2)\n",
    "check_test_dtype(pred2, x2)\n",
    "assert (pred2 == y2).all(), \"Predictions should match the expected labels for model 2.\"\n",
    "\n",
    "pred3 = test_model3.predict(x3)\n",
    "check_test_dtype(pred3, x3)\n",
    "assert (pred3 == y3).all(), \"Predictions should match the expected labels for model 3.\"\n",
    "\n",
    "# Test Model Accuracy\n",
    "def check_accuracy(model, X, y, expected_accuracy):\n",
    "    accuracy = model.accuracy(X, y)\n",
    "    assert accuracy == expected_accuracy, f\"Expected accuracy: {expected_accuracy}, but got: {accuracy}\"\n",
    "\n",
    "# Check accuracy\n",
    "check_accuracy(test_model1, x1, y1, 1.0)  # Expecting 100% accuracy for this simple case\n",
    "check_accuracy(test_model2, x2, y2, 1.0)  # Expecting 100% accuracy for this dataset\n",
    "check_accuracy(test_model3, x3, y3, 1.0)  # Expecting 100% accuracy for this dataset\n",
    "\n",
    "# Additional Tests for Edge Cases\n",
    "def test_empty_train():\n",
    "    with pytest.raises(ValueError):\n",
    "        test_model1.train(np.array([]), np.array([]))\n",
    "\n",
    "def test_empty_predict():\n",
    "    with pytest.raises(ValueError):\n",
    "        test_model1.predict(np.array([]))\n",
    "\n",
    "def test_accuracy_empty():\n",
    "    with pytest.raises(ValueError):\n",
    "        test_model1.accuracy(np.array([]), np.array([]))\n",
    "\n",
    "# Run additional edge case tests\n",
    "test_empty_train()\n",
    "test_empty_predict()\n",
    "test_accuracy_empty()\n",
    "\n",
    "# Print a message indicating the tests have completed\n",
    "print(\"All tests completed successfully.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Weak Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred:  [0 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "     # Create a simple dataset\n",
    "    X = np.array([[0, 0], \n",
    "              [1, 1], \n",
    "              [1, 0], \n",
    "              [0, 1], \n",
    "              [0, 0], \n",
    "              [1, 1]])\n",
    "\n",
    "    # Corresponding labels\n",
    "    y = np.array([0, 0, 1, 1, 0, 1]) # Labels should be -1 and 1 for AdaBoost\n",
    "\n",
    "    # Initialize the AdaBoost classifier\n",
    "    weak_model = DecisionTree(data=np.column_stack((y, X)), max_depth=4) \n",
    "    y_pred = np.zeros_like(y)  # Initialize y_pred\n",
    "    for i, (y_i, x_i) in enumerate(zip(y, X)):\n",
    "        combined_input = np.append(y_i, x_i)\n",
    "        y_pred_i = weak_model.predict(combined_input)  # Predictions from the model\n",
    "        y_pred[i] = y_pred_i  # Update y_pred with the prediction\n",
    "    print(\"y_pred: \", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred:  [0 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "     # Create a simple dataset\n",
    "    X = np.array([[0, 0], \n",
    "              [1, 1], \n",
    "              [1, 0], \n",
    "              [0, 1], \n",
    "              [0, 0], \n",
    "              [1, 1]])\n",
    "\n",
    "    # Corresponding labels\n",
    "    y = np.array([0, 0, 1, 1, 0, 1]) # Labels should be -1 and 1 for AdaBoost\n",
    "\n",
    "    # Initialize the AdaBoost classifier\n",
    "    weak_model = DecisionTree(data=np.column_stack((y, X)), max_depth=2) \n",
    "    y_pred = np.zeros_like(y)  # Initialize y_pred\n",
    "    for i, (y_i, x_i) in enumerate(zip(y, X)):\n",
    "        combined_input = np.append(y_i, x_i)\n",
    "        y_pred_i = weak_model.predict(combined_input)  # Predictions from the model\n",
    "        y_pred[i] = y_pred_i  # Update y_pred with the prediction\n",
    "    print(\"y_pred: \", y_pred)\n",
    "    # Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test model 0.16666666666666663\n",
      "----start-----\n",
      "\n",
      "---START PRINT TREE---\n",
      "split attribute = 3; gain = 0.318257; number of samples = 6\n",
      "0 -> 0\n",
      "1 -> split attribute = 1; gain = 0.174416; number of samples = 3\n",
      "\t\t0 -> 1\n",
      "\t\t1 -> split attribute = 2; gain = 0.693147; number of samples = 2\n",
      "\t\t\t\t0 -> 1\n",
      "\t\t\t\t1 -> 0\n",
      "----END PRINT TREE---\n",
      "training loss: 0.0\n",
      "validation loss: 0.5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "import random\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Tests for node_score_error\n",
    "assert node_score_error(.3) == .3\n",
    "assert node_score_error(.6) == .4\n",
    "\n",
    "# Tests for node_score_entropy\n",
    "assert node_score_entropy(.5) == pytest.approx(.69, .01)\n",
    "assert node_score_entropy(0) == node_score_entropy(1) == 0\n",
    "assert node_score_entropy(.7) == pytest.approx(.61,.01)\n",
    "\n",
    "# Tests for node_score_gini\n",
    "assert node_score_gini(1) == node_score_gini(0) == 0\n",
    "assert node_score_gini(.4) == .48\n",
    "\n",
    "# Creates Test Model and Dummy Data\n",
    "x = np.array([[0,1,0,0],[1,0,1,1],[1,1,0,1],[0,0,1,0],[0,1,1,1],[0,0,0,0]])\n",
    "test_model = DecisionTree(x, gain_function=node_score_entropy)\n",
    "\n",
    "# Test for majority_class\n",
    "assert test_model.majority_class == 0\n",
    "\n",
    "# Tests for _is_terminal\n",
    "node1 = Node(left=None, right=None, depth=0, index_split_on=3, isleaf=False, label=0)\n",
    "x_filtered_node2 = np.array([row for row in x if row[3] == 1])\n",
    "node2 = Node(left=None, right=None, depth=1, index_split_on=1, isleaf=False, label=1)\n",
    "x_filtered_node3 = np.array([row for row in x_filtered_node2 if row[1] == 1])\n",
    "node3 = Node(left=None, right=None, depth=2, index_split_on=2, isleaf=False, label=0)\n",
    "x_filtered_node4 = np.array([row for row in x_filtered_node3 if row[2] == 1])\n",
    "node4 = Node(left=None, right=None, depth=3, index_split_on=None, isleaf=True, label=0)\n",
    "\n",
    "assert test_model._is_terminal(node=node1, data=x, indices=[1, 2, 3]) == (False, 0)\n",
    "assert test_model._is_terminal(node=node2, data=x_filtered_node2, indices=[1, 2]) == (False, 1)\n",
    "assert test_model._is_terminal(node=node3, data=x_filtered_node3, indices=[2]) == (False, 0)\n",
    "assert test_model._is_terminal(node=node4, data=x_filtered_node4, indices=[]) == (True, 0)\n",
    "\n",
    "# Tests _calc_gain\n",
    "# Testing gain for index 3\n",
    "print(\"test model\", test_model._calc_gain(x, 3, node_score_error))\n",
    "print(\"----start-----\")\n",
    "print()\n",
    "assert test_model._calc_gain(x, 3, node_score_error) == pytest.approx(0.166, .01)\n",
    "\n",
    "assert test_model._calc_gain(x, 3, node_score_entropy) == pytest.approx(0.318, .01)\n",
    "assert test_model._calc_gain(x, 3, node_score_gini) == pytest.approx(0.222, .01)\n",
    "\n",
    "# Testing gain for index 1\n",
    "assert test_model._calc_gain(x_filtered_node2, 1, node_score_error) == pytest.approx(5.551115123125783e-17, abs=1e-18)\n",
    "assert test_model._calc_gain(x_filtered_node2, 1, node_score_entropy) == pytest.approx(0.174, .01)\n",
    "assert test_model._calc_gain(x_filtered_node2, 1, node_score_gini) == pytest.approx(0.111, .01)\n",
    "\n",
    "# Testing gain for index 2\n",
    "assert test_model._calc_gain(x_filtered_node3, 2, node_score_error) == pytest.approx(0.5, .01)\n",
    "assert test_model._calc_gain(x_filtered_node3, 2, node_score_entropy) == pytest.approx(0.693, .01)\n",
    "assert test_model._calc_gain(x_filtered_node3, 2, node_score_gini) == pytest.approx(0.5, .01)\n",
    "\n",
    "# Check Tree is created Properly, Compare with text below\n",
    "'''\n",
    "Decision Trees should look similar to below (the second one is the pruned tree)\n",
    "\n",
    "---START PRINT TREE---\n",
    "split attribute = 3; gain = 0.318257; number of samples = 6\n",
    "0 -> False\n",
    "1 -> split attribute = 1; gain = 0.174416; number of samples = 3\n",
    "\t\t0 -> True\n",
    "\t\t1 -> split attribute = 2; gain = 0.693147; number of samples = 2\n",
    "\t\t\t\t0 -> True\n",
    "\t\t\t\t1 -> False\n",
    "----END PRINT TREE---\n",
    "'''\n",
    "test_model.print_tree()\n",
    "\n",
    "# check loss\n",
    "print('training loss:', test_model.loss(x))\n",
    "x_val = np.array([[1,1,1,1],[1,0,0,1]])\n",
    "print('validation loss:', test_model.loss(x_val), '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Apply to Previous Work**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Previous Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For previous work, we choose **scikit-learn's implementation of AdaBoost (AdaBoostClassifier)** with a shallow decision tree (DecisionTreeClassifier) as the base estimator.\n",
    "We apply scikit-learn's AdaBoost model to the **mushroom dataset**(\"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"), which comprises 23 binary features describing mushroom characteristics, such as shape, color, and odor, with a binary target indicating edibility (-1 for edible, 1 for poisonous). The model achieves high accuracy, demonstrating the power of AdaBoost in correctly classifying tumors. Below is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.98      0.98       843\n",
      "           1       0.98      0.98      0.98       782\n",
      "\n",
      "    accuracy                           0.98      1625\n",
      "   macro avg       0.98      0.98      0.98      1625\n",
      "weighted avg       0.98      0.98      0.98      1625\n",
      "\n",
      "Model accuracy:  0.9821538461538462\n"
     ]
    }
   ],
   "source": [
    "# Load the Mushroom Dataset from UCI repository\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier as AdaBoostClassifier_sklearn\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# URL for Mushroom dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
    "\n",
    "# Column names for the dataset as per UCI documentation\n",
    "columns = [\n",
    "    \"class\", \"cap-shape\", \"cap-surface\", \"cap-color\", \"bruises\", \"odor\",\n",
    "    \"gill-attachment\", \"gill-spacing\", \"gill-size\", \"gill-color\",\n",
    "    \"stalk-shape\", \"stalk-root\", \"stalk-surface-above-ring\",\n",
    "    \"stalk-surface-below-ring\", \"stalk-color-above-ring\",\n",
    "    \"stalk-color-below-ring\", \"veil-type\", \"veil-color\", \"ring-number\",\n",
    "    \"ring-type\", \"spore-print-color\", \"population\", \"habitat\"\n",
    "]\n",
    "\n",
    "# Load dataset\n",
    "mushroom_data = pd.read_csv(url, header=None, names=columns)\n",
    "\n",
    "# Preprocess the data\n",
    "# Convert categorical variables into binary using one-hot encoding\n",
    "# Convert 'class' column (edible=e, poisonous=p) into binary labels\n",
    "mushroom_data[\"class\"] = mushroom_data[\"class\"].apply(lambda x: 1 if x == \"p\" else -1)\n",
    "mushroom_data_encoded = pd.get_dummies(mushroom_data.drop(columns=[\"class\"]))\n",
    "\n",
    "# Combine the binary features with the target\n",
    "mushroom_dataset = pd.concat([mushroom_data[\"class\"], mushroom_data_encoded], axis=1)\n",
    "\n",
    "X = mushroom_dataset.drop(columns=[\"class\"])\n",
    "y = mushroom_dataset[\"class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
    "adaboost = AdaBoostClassifier_sklearn(estimator=base_estimator, algorithm='SAMME', n_estimators=10, learning_rate=1, random_state=42)\n",
    "\n",
    "# Train AdaBoost classifier\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = adaboost.predict(X_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.Blues)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(class_report)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = adaboost.score(X_test, y_test)\n",
    "print(\"Model accuracy: \", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduce previous work using our model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce the previous work, we simply replace AdaBoostClassifier_sklearn from sklearn in previous work with our implemented model AdaBoostClassifier. Below is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.98      0.98       843\n",
      "           1       0.98      0.98      0.98       782\n",
      "\n",
      "    accuracy                           0.98      1625\n",
      "   macro avg       0.98      0.98      0.98      1625\n",
      "weighted avg       0.98      0.98      0.98      1625\n",
      "\n",
      "Model accuracy:  0.9821538461538462\n"
     ]
    }
   ],
   "source": [
    "# URL for Mushroom dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
    "\n",
    "# Column names for the dataset as per UCI documentation\n",
    "columns = [\n",
    "    \"class\", \"cap-shape\", \"cap-surface\", \"cap-color\", \"bruises\", \"odor\",\n",
    "    \"gill-attachment\", \"gill-spacing\", \"gill-size\", \"gill-color\",\n",
    "    \"stalk-shape\", \"stalk-root\", \"stalk-surface-above-ring\",\n",
    "    \"stalk-surface-below-ring\", \"stalk-color-above-ring\",\n",
    "    \"stalk-color-below-ring\", \"veil-type\", \"veil-color\", \"ring-number\",\n",
    "    \"ring-type\", \"spore-print-color\", \"population\", \"habitat\"\n",
    "]\n",
    "\n",
    "# Load dataset\n",
    "mushroom_data = pd.read_csv(url, header=None, names=columns)\n",
    "\n",
    "# Preprocess the data\n",
    "# Convert categorical variables into binary using one-hot encoding\n",
    "# Convert 'class' column (edible=e, poisonous=p) into binary labels\n",
    "mushroom_data[\"class\"] = mushroom_data[\"class\"].apply(lambda x: 1 if x == \"p\" else -1)\n",
    "mushroom_data_encoded = pd.get_dummies(mushroom_data.drop(columns=[\"class\"]))\n",
    "\n",
    "# Combine the binary features with the target\n",
    "mushroom_dataset = pd.concat([mushroom_data[\"class\"], mushroom_data_encoded], axis=1)\n",
    "\n",
    "X = mushroom_dataset.drop(columns=[\"class\"])\n",
    "y = mushroom_dataset[\"class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "adaboost = AdaBoostClassifier(n_estimators=10, max_depth=1)\n",
    "adaboost.train(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = adaboost.predict(X_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.Blues)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(class_report)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = adaboost.accuracy(X_test, y_test)\n",
    "print(\"Model accuracy: \", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our own implemented model reproduces the same results from the sklearn model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data2060",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "544ac37830e19c29de6048fe684bce153ff51a4b90e76219d27d111f4b1ba956"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
